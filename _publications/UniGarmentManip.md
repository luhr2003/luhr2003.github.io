---
title: "UniGarmentManip: A Unified Framework for Category-Level Garment Manipulation via Dense Visual Correspondence"
collection: publications
permalink: /publication/unigarmentmanip
excerpt: 'We propose to learn dense visual correspondence for diverse garment manipulation tasks with category-level generalization using only one- or few-shot human demonstrations. '
date: 2024-02-01
venue: 'CVPR 2024'
author: "Ruihai Wu*, Haoran Lu*, Yiyan Wang, Yubo Wang, Hao Dong"
code_url: "https://github.com/luhr2003/UniGarmentManip"
project_url: "https://warshallrho.github.io/unigarmentmanip/"
paper_url: "https://ieeexplore.ieee.org/document/10657950?denied="
award: "Spotlight Presentation"
award_venue: "ICRA 2024 Workshop on Deformable Object Manipulation"
head.teaser: "unigarmentmanip.png"
---
<style>
    .light-red {
        color: lightcoral; /* 浅红色的一种 */
    }
</style>

We propose to learn dense visual correspondence for diverse garment manipulation tasks with category-level generalization using only one- or few-shot human demonstrations. 

CVPR 2024 

<span class="light-red"> Spotlight Presentation</span> at ICRA 2024 Workshop on Deformable Object Manipulation

[Paper](https://ieeexplore.ieee.org/document/10657950/?denied=) / [Code](https://github.com/luhr2003/UniGarmentManip) / [Project Page](https://warshallrho.github.io/unigarmentmanip/)

