---
title: "UniGarmentManip: A Unified Framework for Category-Level Garment Manipulation via Dense Visual Correspondence"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2024-02-01
venue: 'CVPR 2024'
paperurl: 'https://warshallrho.github.io/unigarmentmanip/'
---
<style>
    .light-red {
        color: lightcoral; /* 浅红色的一种 */
    }
</style>

We propose to learn dense visual correspondence for diverse garment manipulation tasks with category-level generalization using only one- or few-shot human demonstrations. 

CVPR 2024 

<span class="light-red"> Spotlight Presentation</span> at ICRA 2024 Workshop on Deformable Object Manipulation

[Paper](https://ieeexplore.ieee.org/document/10657950/?denied=) / [Code](https://github.com/luhr2003/UniGarmentManip) / [Project Page](https://warshallrho.github.io/unigarmentmanip/)

