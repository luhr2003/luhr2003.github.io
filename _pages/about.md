---
permalink: /
title: "Haoran Lu"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<style>
    .darkred-bold {
        color: darkred;
        font-weight: bold;
    }
</style>


I am a fourth-year student at the school of EECS of Peking University majoring in Computer Science and Economics, advised by [Prof. HaoDong](https://zsdonghao.github.io/). My research interests primarily focus on computer vision and robotics. 
Currently, I am privileged to be advised by [Prof. Yunzhu Li](https://yunzhuli.github.io/) and [Prof. Alan L. Yuille](https://www.cs.jhu.edu/~ayuille/)


[Email](luhr@stu.pku.edu.cn) / [Google Scholar](https://scholar.google.com/citations?user=8Z6Z9QoAAAAJ&hl=en) / [Github](https://github.com/luhr2003)

Looking for Ph.D. Position
======
**I am looking for a Ph.D. position starting from Fall 2025.**


Feel free to drop me an [email](mailto luhr@stu.pku.edu.cn) if you are interested in my research or have any questions.

Here is my [CV](../assets/CV_Haoran_Lu.pdf) and [Research Statement](../assets/Research_Statement_Haoran_Lu.pdf).

News
======
+ [2024.09] Our paper [GarmentLab](https://garmentlab.github.io/) is accepted by NeurIPS 2024.
+ [2024.05] One paper get accepted by RSS 2024.
+ [2024.03] Our paper [UniGarmentManip](https://warshallrho.github.io/unigarmentmanip/) is accepted by CVPR 2024.
+ [2023.09] Our Paper [Where2Explore](https://tritiumr.github.io/Where2Explore/) is accepted by NeurIPS 2023.


Research Interest
======
I am passionate about the intersection of <span class="darkred-bold">Computer vision and Robotics</span> and aim to significantly expand robots' perception abilities. My research interests include:
+ <span class="darkred-bold">Computer Vision</span> : I mainly focus on 3D representation learning, 3D scene understanding and 3D reconstruction.
+ <span class="darkred-bold">Robotics</span> : I am interested in robot perception, control and simulation. I mainly focus on visual and tactile perception and deformable object manipulation.
+ <span class="darkred-bold">VLM</span> : I am also excited about Visual Large Language Model, especially the application of VLM in robotics.



